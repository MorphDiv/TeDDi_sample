---
title: "100LC Unigram Entropy Estimation"
author: "Chris Bentz"
date: "May 15, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This file explains how to use frequency lists of characters and orthographic words to estimate "unigram entropies". Unigram entropy here means that characters and words are seen as independent units of information encoding, i.e. not depending on the co-text. Hence, the unigram entropy directly reflects the distribution of frequencies of occurrence of the units. 

##Load libraries
If libraries are not yet installed, use install.packages("package-name") to install them.
```{r}
library(ggplot2)
library(gridExtra)
library(entropy)
```

## Examples for Code Illustration
Specify paths to different tokenized and linearized text files for illustrating the workings of entropy estimation.
```{r}
file.words <- "/home/chris/Data/100LC/Texts/FreqLists/Words/rus_pro_1.txt" 
file.chars <- "/home/chris/Data/100LC/Texts/FreqLists/Characters/rus_pro_1.txt" 
```

Read files.
```{r}
words <- read.csv(file.words)
head(words)
chars <- read.csv(file.chars)
head(chars)
```

Use the entropy() function to calculate the unigram entropy for characters and words. Here, the method is set to "ML", i.e. maximum likelihood. The ML method simply assumes that the probability of a unit is its frequency divided by the sum of frequencies of units, i.e. the overall number of character or word tokens in a given text. Other, more advanced methods are also avalaible via this package.
```{r}
H.ML.chars <- entropy(chars$Freq, method = "ML", unit = "log2")
print(H.ML.chars)
H.ML.words <- entropy(words$Freq, method = "ML", unit = "log2")
print(H.ML.words)
```

## Application
Apply unigram entropy estimation to all frequency lists.

### Characters
Read all paths to tokenized files in a given folder. 
```{r}
files <- list.files(path = "/home/chris/Data/100LC/Texts/FreqLists/Characters", full.names = T)
head(files)
```

For-loop to get unigram entropy estimations by the ML method. Note that the metadata for each text now has to be added to the output file in order for the file to be useful for later analyses. 
```{r}
# ptime <- proc.time() # get system time before starting process
# for (file in files) {
#   chars <- read.csv(file)
#   H.ML <- entropy(chars$Freq, method = "ML", unit = "log2") 
#   # add metadata
#   file.name <- basename(file)
#   iso <- substring(basename(file), 1, 3)
#   size <- sum(chars$Freq)
#   H.df <- data.frame(file.name, iso, size, H.ML)
#   write.table(H.df, file = "/home/chris/Data/100LC/Texts/Entropy/unigramH_chars.csv", 
#               sep = ",", append = T, row.names = F, col.names = F)  
#   #show(file.name)
# }
# proc.time() - ptime # show time elapsed while processing
```

Finally, add the column names to the output file with entropy estimations.
```{r}
H.file <- read.csv("/home/chris/Data/100LC/Texts/Entropy/unigramH_chars.csv", header = F)
colnames(H.file) <- c("file.name", "iso", "num.tokens", "H.chars")
write.csv(H.file, "/home/chris/Data/100LC/Texts/Entropy/unigramH_chars.csv", row.names = F) 
```

### Words
Read all paths to tokenized files in a given folder. 
```{r}
files <- list.files(path = "/home/chris/Data/100LC/Texts/FreqLists/Words", full.names = T)
head(files)
```

For-loop to get unigram entropy estimations by the ML method. Note that the metadata for each text now has to be added to the output file in order for the file to be useful for later analyses. 
```{r}
# ptime <- proc.time() # get system time before starting process
# for (file in files) {
#   words <- read.csv(file)
#   H.ML <- entropy(words$Freq, method = "ML", unit = "log2") 
#   # add metadata
#   file.name <- basename(file)
#   iso <- substring(basename(file), 1, 3)
#   size <- sum(words$Freq)
#   H.df <- data.frame(file.name, iso, size, H.ML)
#   write.table(H.df, file = "/home/chris/Data/100LC/Texts/Entropy/unigramH_words.csv", 
#               sep = ",", append = T, row.names = F, col.names = F)  
#   #show(file.name)
# }
# proc.time() - ptime # show time elapsed while processing
```

Finally, add the column names to the output file with entropy estimations.
```{r}
H.file <- read.csv("/home/chris/Data/100LC/Texts/Entropy/unigramH_words.csv", header = F)
colnames(H.file) <- c("file.name", "iso", "num.tokens", "H.words")
write.csv(H.file, "/home/chris/Data/100LC/Texts/Entropy/unigramH_words.csv", row.names = F) 
```

---
title: "Get line and file counts for the 100LC corpora by genre"
author: "Steven Moran"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
  pandoc_args: --webtex
---

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
```

# Overview

Calculate line counts from database version of the 100LC corpus. These include total line counts, total file counts, for each language and for each genre represented by each language.

Then compare them with the [pre-database Python script](../progress/line_counts.py) that counts these figures directly from the text files.


# Generate line and files counts from the database

Load the R serialized version of the 100LC database.

```{r}
# load('../../Database/test.RData') # for testing
load('../../Database/100LC.Rdata') # full database
```

First, remove all NAs (NULLs) in the `clc_line.text` field in the database, i.e. any empty lines due to issues such as tags without text, so that we get correct counts:

```{r}
clc_line <- clc_line %>% filter(!is.na(text))
```

Then, get the total line counts per file.

```{r}
total_lines_per_file <- clc_line %>% select(file_id, id) %>% distinct() %>% group_by(file_id) %>% summarize(total_lines = n())
```

Now add in the file metadata. This gives us everything we need to caculate the genre specific number of lines and files per language, and also their totals.

```{r}
file_metadata <- clc_file %>% select(id, language_name_wals, genre_broad)
all <- left_join(total_lines_per_file, file_metadata, by=c("file_id"="id"))
rm(total_lines_per_file)
all %>% head() %>% kable()
```

Total lines per language.

```{r}
total_lines <- all %>% select(language_name_wals, total_lines) %>% group_by(language_name_wals) %>% summarize(db_total_lines = sum(total_lines))
total_lines %>% head() %>% kable()
```

Total lines by language and genre.

```{r}
total_lines_per_genre <- all %>% select(language_name_wals, genre_broad, total_lines) %>% group_by(language_name_wals, genre_broad) %>% summarize(genre_lines=sum(total_lines))
total_lines_per_genre %>% head() %>% kable()
```

Total files per language.

```{r}
total_files <- all %>% select(language_name_wals, file_id) %>% group_by(language_name_wals) %>% summarize(db_total_files = n())
total_files %>% head() %>% kable()
```

Total files per genre.

```{r}
total_files_per_genre <- all %>% select(file_id, language_name_wals, genre_broad) %>% group_by(language_name_wals, genre_broad) %>% summarize(genre_files = n())
total_files_per_genre %>% head() %>% kable()
```

Now convert the output of grouping and counting by genres to wide format for merging. Note there will be many NA cells.

```{r}
total_files_per_genre_wide <- spread(total_files_per_genre, key = genre_broad, value = genre_files)
total_files_per_genre_wide %>% head() %>% kable()
```

Now for the lines per genre.

```{r}
total_lines_per_genre_wide <- spread(total_lines_per_genre, key = genre_broad, value = genre_lines)
total_lines_per_genre_wide %>% head() %>% kable()
```

Finally, rename the columns to match the [pre-database Python script's output](../progress/line_counts.csv). 

```{r}
total_files_per_genre_wide <- total_files_per_genre_wide %>% rename(db_conversation_files = conversation, db_fiction_files = fiction, db_grammar_files = grammar, db_non_fiction_files = 'non-fiction', db_professional_files = professional)

total_lines_per_genre_wide <- total_lines_per_genre_wide %>% rename(db_conversation_lines = conversation, db_fiction_lines = fiction, db_grammar_lines = grammar, db_non_fiction_lines = 'non-fiction', db_professional_lines = professional)
```

Combine the data frames counts and add in the missing values, i.e. languages without data as indicated in the [langInfo_100LC.csv](../../LangInfo/langInfo_100LC.csv) index.

```{r}
db_report <- left_join(total_files, total_lines)
db_report <- left_join(db_report, total_files_per_genre_wide)
db_report <- left_join(db_report, total_lines_per_genre_wide)

index <- read.csv('../../LangInfo/langInfo_100LC.csv')
missing.languages <- index %>% filter(is.na(name)) %>% select(name_wals)
missing.languages <- missing.languages %>% rename(name=name_wals)

db_report <- db_report %>% add_row(language_name_wals=missing.languages$name)
```

Lastly, let's add the 100LC corpus names for convenience for matching with the progress report.

```{r}
corpus_names <- index %>% select(name_wals, name)
db_report <- left_join(db_report, corpus_names, by=c("language_name_wals" = "name_wals"))
```

How's it look?

```{r}
kable(db_report)
```

Let's write the table to disk.

```{r}
write_csv(db_report, 'line_counts.csv')
```

Let's clean up of the workspace.

```{r}
rm(list = ls())
```


# Compare the database vs the Python reports

Read in Olga's report (Python script's output that examines the corpus files directly) from the [progress](../progress/) report.

```{r}
report <- read.csv('../progress/line_counts.csv')
```

Read in the database report.

```{r}
db_report <- read_csv('line_counts.csv')
```

Combine the reports for comparison.

```{r}
combined_reports <- left_join(report, db_report, by=c('language' = 'name'))
combined_reports$delta_total_lines <- abs(combined_reports$total_lines-combined_reports$db_total_lines)
```

Reorder the report to make it easier to compare.

```{r}
combined_reports <- combined_reports %>% select(language, total_files, db_total_files, fiction_files, db_fiction_files ,non.fiction_files, db_non_fiction_files, conversation_files, db_conversation_files, professional_files, db_professional_files, grammar_files, db_grammar_files, fiction_lines, db_fiction_lines, non.fiction_lines, db_non_fiction_lines, conversation_lines, db_conversation_lines, professional_lines, db_professional_lines, grammar_lines, db_grammar_lines, total_lines, db_total_lines, delta_total_lines)
```

The combined reports.

```{r}
kable(combined_reports)
```

Write the comparison report to disk.

```{r}
write.csv(combined_reports, file="compared_reports2.csv", quote=FALSE, row.names=FALSE)
```

Clean up.

```{r}
rm(list = ls())
```


---
title: "Word TTR in 100LC"
author: "Steven Moran"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
  pandoc_args: --webtex
---

Generate word type-token ratios for the 100LC corpus data.

```{r echo=FALSE, include=FALSE}
library(dplyr)
library(RSQLite)
```

Query the database and return a dataframe.

```{r}
db.file <- '../../Database/words.sqlite3' # Test data
# db.file <- '../../Database/full.sqlite3'

runsql <- function(sql, dbname=db.file){
  require(RSQLite)
  driver <- dbDriver("SQLite")
  connect <- dbConnect(driver, dbname=dbname);
  closeup <- function(){
    sqliteCloseConnection(connect)
    sqliteCloseDriver(driver)
  }
  dd <- tryCatch(dbGetQuery(connect, sql), finally=closeup)
  return(dd)
}
```

Get the word token counts.

```{r}
tokens <- runsql('
SELECT name, writing_system, count(*) 
FROM v_words 
GROUP BY name, writing_system
')

tokens <- tokens %>% rename(tokens = `count(*)`)
```

Get word type counts.

```{r}
types <- runsql('
SELECT name, writing_system, word_text, count(*) 
FROM v_words 
GROUP BY name, writing_system, word_text
')
```

Make sure the sum of counts is correct from SQL.

```{r}
test <- types %>% filter(name=='Abkhaz_abk') %>% filter(writing_system=='Cyrl') %>% select('count(*)')
sum(test$`count(*)`)
```

Get the type counts.

```{r}
types <- types %>% group_by(name, writing_system) %>% summarize(types=n())
```

Join the type and token counts into a single data frame.

```{r}
ttr <- left_join(types, tokens)
```

Calculate the type-token ratio: (number of types/number of tokens) * 100.

```{r}
ttr$ttr <- (ttr$types / ttr$tokens) * 100
```

A table if TTR values:

```{r}
library(knitr)
ttr %>% kable()
```

Plot the languages by their TTR ratios.

```{r}
library(ggplot2)
p <- ttr
p$name <- factor(p$name, levels = p$name[order(ttr$ttr)])
qplot(name, ttr, data=p) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Write the table to CSV.

```{r}
write.csv(ttr, file="words_ttr.csv", row.names=FALSE)
```
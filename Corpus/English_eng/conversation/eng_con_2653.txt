# language_name_wals:	English
# language_name_glotto:	English
# iso639_3:	eng
# year_composed:	NA
# year_published:	1998
# mode:	written
# genre_broad:	conversation
# genre_narrow:	NA
# writing_system:	Latn
# special_characters:	NA
# short_description:	ca
# source:	https://ca.talkbank.org/data-orig/MICASE/office_hours/ofc575mu046.cha
# copyright_short:	https://sla.talkbank.org/TBB/ca
# copyright_long:	CABank: MacWhinney, B., & Wagner, J. (2010). Transcribing, searching and data sharing: The CLAN software and the TalkBank data repository. Gesprachsforschung, 11, 154-173.
# sample_type:	whole
# comments:	NA
numerical value or your cutoff value the point that indicates where you should reject and where you should accept h@l naught depending on which side you fall . 2005_8585
and then so that would +//. 9325_10845
like assuming that these are the right numbers +/. 11885_13165
right .
+, that would be ⌈ the number ⌉ +/. 13445_15145
+, ⌊ compared ⌋ +/.
+, that I get and I would compare that to the value on the chart . 15345_20245
right . 20545_20565
⌈ exactly ⌉ .
⌊ and if ⌋ the value on the chart is smaller or larger ? 20805_23065
well it depends on what your h@l one and h@l naught look like you need to set up your hypotheses so there's really some good you know there's some good practice to start identifying and doing with each problem alright ? 23235_32395
set up h@l naught and h@l one and write that down even if it's in the text already you know telling you to test these hypotheses write it out so you visually see it each time . 32595_39855
so you identify in particular h@l one which tells you what direction (be)cause that direction will tell you whether you reject if it's small large or what way you go . 40215_48795
okay ? 49475_49555
do you have a little piece of tape ? 50155_51335
mhm .
thanks +...
so &~an setting up h@l naught and h@l one . 51375_57475
in this example four eleven you're trying to see there is a significant difference in the effectiveness . 57875_63595
when you hear the phrase is there a difference or not you're not looking for A being better than B or B being better than A you're just looking for a difference . 64935_71555
so if the differences are all about zero on average there's really no difference between the two methods . 72675_77795
if the difference on average is not zero then you say there is a significant difference . 79185_84745
so I'm looking for a two sided test . 85385_87005
okay ?
⌈ so ⌉ +/. 88265_88965
⌊ this is ⌋ +/.
+, any difference as long as it doesn't turn out to be the exact same thing ? 89285_92265
mm I mean what what you're gonna be doing then is you're gonna seeing the differences were what ? 92405_96005
five negative one two there's some negatives some positives and you're trying to say whether they on average are about zero or whether on average they are different from zero . 96405_104565
mkay and you're gonna &~ches tecks check that with some significance level mkay ? 105645_110425
so you wanna set up hypotheses and h@l one is the one that will gear what your region looks like overall okay ? 110905_117205
mm &-um when is it appropriate to use a t@l test and when isn't it ? 117845_120925
well you have a couple different t@l tests . 121185_122665
all the t@l tests so far though are really geared at what type of assumption that your sample sizes are ⌈ small ⌉ . 123325_128405
⌊ small ⌋ .
mhm you do the z@l test versions where we have them if your sample sizes are large (be)cause really what you're doing is falling off that t@l table and going to the z@l percentiles anyway . 129905_138305
you're basically doing it as if it's a normal distribution overall . 138925_141565
mkay when is a good point to decide whether it's larger or small though ? 142445_145405
what was the cutoff we mentioned ? 145425_146305
⌈ thirty ⌉ . 146505_146985
⌊ thirty ⌋ thirty observations is the rule of thumb the book uses and so that's the rule of thumb we'll use too . 147345_151025
you guys can pull up a table top you can sit on the floor over here maybe we can move this case possibly +... 151605_157685
is that alright ? 160385_160965
just +/. 161465_161625
⌈ yes ⌉ +/.
+, ⌊ so it's ⌋ out_of the way +/. 161925_162225
+, yes .
+, we can get more people here . 162425_163245
I have a question about four point nine just +/. 163765_166065
mhm .
+, a small part of it &-um I figured +//. 166585_169625
I did the whole problem and figured out d@l bar +/. 170005_173185
+, mhm .
+, and s@l sub d@l but that I think is where I had the problem I didn't +//. 174485_179125
+, mhm +/.
+, I got eighty one for that and . 179445_180785
mm you ⌈ should have a ⌉ +/. 181305_182165
⌊ you had ⌋ +/.
+, whole range of values that you square here . 182265_184325
⌈ this is ⌉ . 185385_185605
⌊ how do you mean ⌋ ?
see that's a sum that means &~y . 185725_186665
right .
right . 186805_186905
but the sum of DI is thirty I added all those . 187735_191055
nope that's not the sum of DI it's the sum of these differences squared across each difference you do it for each difference you take two minus three squared ⌈ eight minus three squared ⌉ . 191395_202495
⌊ ah oh ⌋ oh I see . 202715_203155
ten minus three negative eight minus three and square all those . 203175_205995
oh that's so long . 206075_207215
yeah it is long but you have a cal@u +//. 207355_208675
is this yours ? 208675_209195
&-um yeah . 209655_210135
you have the ability to do it right in there . 210275_211955
I know . 212195_212395
+, yeah .
okay ? 212935_213235
+, okay . 213375_213635
+, and if you can +//. 213775_214135
you know all it means is entering these differences in a list +/. 214015_216575
+, okay .
+, and doing your one variable summary measures . 217415_218975
+, okay .
+, okay ?
+, mhm +/.
+, and get it that way . 219815_220575
+, okay .
+, and in general that number is easy to be calculated or it will be so easy that the differences will come very nicely . 221135_226075
⌈ I have +//. 226455_227155
I ⌉ .
⌊ how do you do stuff on the ⌋ +/.
mhm +/.
+, on a calculator .
what calculator do you have ? 228775_229755
TI eighty five .
mkay eighty five I'm not as familiar with overall what I might wanna suggest is maybe at the end of the session I can show you a couple things . 230155_237015
okay ? 237215_237355
mhm ?
&-uh as far as four point nine +/. 237655_240075
mhm +/.
+, &-um for the ninety eight percent confidence interval +/. 240735_242695
+, right . 243095_243115
+, without an alpha . 243555_244155
you &~alr you have a alpha . 245015_246075
we do ? 246235_246495
what's the ninety eight percent giving you really ? 246735_248355
oh true we already have +/. 248795_250095
yeah .
+, oh never mind .
okay . 250195_251175
&=laughs .
okay +/. 252755_253175
yep .
+, alright .
&-um I wanted to ask about what number was that ? 253755_256695
two point five . 257895_259055
two point five ? 259555_260275
yeah the answer in the book was not what I got and I wanted to make sure +//. 260315_263435
I wanted to see ⌈ if it was wrong ⌉ . 263835_264275
⌊ answer in the ⌋ book is not guaranteed to be right . 264275_265835
&=laughs:S10 mhm .
with that many questions that they're giving answers for they may get some wrong . 267265_270665
yeah .
+, two point five is doing the test on the previous exercise data that there is a higher mean response for treatment one and these are &~l definitely large sample sizes seventy nine and sixty two so what did we do for our your your test statistic in particular is that what you're looking at ? 272285_290725
yeah . 290885_291005
mhm .
+, mhm .
we are looking for a direction here it's going to be a z@l statistic . 294675_297055
what did you get for your z@l statistic value ? 298575_300515
I got negative two point nine four . 300675_302275
&-uh I have negative two point two two but I'm . 302815_305995
that's what it said ⌈ in the back of the book ⌉ .
⌊ that's what I got ⌋ . 305995_306515
no that may be that's all they typed up then . 307055_308935
it's negative two point two two (be)cause that's what I got . 309455_311055
that's what I got . 311055_311295
yep okay so you might need to check whether you plugged in your sample variances correctly or your sample &~s standard deviations ? 311315_318135
is the &-um +//. 318155_319275
&~i is it the top . 320655_321655
what did you get for the numerator ? 322435_323115
for the numerator I got negative nineteen . 323495_325035
correct . 325275_325635
and then for the bottom I got six point four seven . 325915_327835
that should be about eight and a half . 328015_329255
okay . 329395_329655
so check the calculation on the bottom . 329755_331175
mhm ?
I have a question on those like it +//. 332995_335235
does it matter what order you put when it says like the &~grou the different groups like the X ⌈ and ⌉ +/. 335575_341955
⌊ this ⌋ +/.
+, the Y you have to &~mi which ones you have to minus like the &~tr . 342095_344315
in general we +//. 344555_345675
if it has a one and a two label to it we'll call one group one and call that x@l bar . 345815_350675
okay .
+, and two group two and call it y@l bar just for consistency purposes . 351515_354195
but and it +//. 355175_355695
you just need to know +//. 356035_356555
and it really truly doesn't matter which way you do it (be)cause if you did your confidence interval switching (th)em around instead of getting a confidence interval and going from two to eight you've got it going from negative eight to negative two . 356855_365775
so that doesn't matter . 366115_366635
it doesn't matter +/. 366815_367235
okay .
+, you make the same decision it's just that keep it in mind which direction then you're going if it's a direction you're headed . 367235_371175
if you're trying to say one's better than the other then you should have certain types of numbers positive or negative . 371545_375805
so it truly does not matter . 376705_377785
but if it &~d is set up you know the X data is this here's group one then keep it that way . 378765_383685
mhm .
⌈ alright ⌉ .
⌊ &-uh ⌋ for two point two three &~i I really don't think there's an alpha for that one . 384285_390345
okay well you're sure about that huh ? 390805_392285
&=laughs I don't know now I'm not so sure but . 392285_394105
okay . 394285_394585
there really isn't but . 395565_396685
⌈ two point ⌉ . 397485_397845
⌊ don't you just ⌋ assume point o@l five is alpha ? 398105_399785
well there's a couple ways to go . 400025_401645
take the assumptions and test +... 401905_404245
true they don't give you an alpha what do you get though let's see what the result is (0.5) oh they don't okay &-um what do you get overall for your test statistic +... 407285_420205
in two point two three ? 422745_423385
&-um <I didn't> I didn't do it (be)cause I didn't know . 424265_426405
okay .
negative two point five seven . 427165_427925
mkay negative two point five seven is good ? 428125_431245
how do &~yo +/.
+, mhm negative two point five seven is your test statistic . 431405_436405
+, mhm +/.
+, you wanna still find the p@l values you normally would and then point o@l five is a good rule of thumb to use in general . 436765_442125
what I would do though is check the answer with both one five and ten percent all three because then you might say well if I make the decision that it's the same for all three of those then I pretty much know what my decision should be okay ? 442705_453265
if your p@l value turns out to be so small that you'd reject for all those levels then go ahead and say so . 453685_458185
if it's in between for some alphas you'd reject for some you wouldn't then say you know for alpha point o@l five we would reject h@l naught however if alpha were one percent we would not quite reject h@l naught and then you're recording your results you're telling me you know how to do a test if alpha were given +/. 458985_473385
+, mhm .
+, in an exam we generally will give you the specified alpha (be)cause in any clinical study or anything there is a determined alpha that is set ahead of time . 474545_480785
so you will have that given . 481185_482325
could I see the answer for four point nine ? 482925_484685
okay these I have not checked so I'm just looking (th)em over +/. 485005_488125
oh okay +/.
+, and I'll be checking &~t over in general . 488285_490345
&-um .
four point nine +/. 491685_493185
yeah .
+, is a confidence interval . 493385_494025
yeah for SD I got two point seven five . 494505_496925
nope SD I have five point eight now again I don't +//. 497185_501125
haven't checked these myself . 501345_502045
I have five point eight too . 502065_502765
five point eight also . 502785_503585
okay did you enter (th)em in l@l one ? 504345_506005
try entering these numbers into l@l one do you know how to do that ⌈ on your ⌉ +/. 506985_509245
⌊ no ⌋ +/.
+, calculator ?
alright we need a little calculator session at the end of of time today okay ? 509725_513065
(be)cause it is nice and easy to do it that way . 513325_515265
okay .
do I square each one separately ? 515565_518025
yep . 518225_518265
+, two minus three squared +/. 518265_519065
+, yep .
+, plus eight minus three squared ? 519425_520445
yep yep . 520565_521245
and your degree +//. 521945_522925
you had ten observations ? 523025_523785
mhm .
yeah . 524245_524505
yep +/. 524765_525085
+, and then square root of that . 525265_526065
yep that is the right approach okay ? 526145_527705
mhm .
so it may be that maybe ⌈ minusing@n$part a negative you did ⌉ +/. 527965_530765
⌊ okay I just did it wrong ⌋ . 530925_531025
+, something wrong . 531025_531345
+, okay . 531585_531845
+, okay . 532085_532365
good . 532705_533045
&-um I don't know how to do this like in two point one three I couldn't I can't figure out how to do this kind of part B . 533305_541145
two point one three ? 542765_544105
yeah . 544305_544485
okay that's the one that's a little different I mentioned in a lecture a little bit . 544665_548325
most of the time our hypotheses in this chapter chapter ten are looking for a hypothesized value of being zero right +/. 548565_556445
mhm +/.
+, (be)cause you're looking for whether the two are equivalent or that they're not and maybe they're not in a certain way here's one where they actually wanted you to test something that wasn't zero . 557085_564765
+, yeah .
+, but it's still the easiest thing to do alright ? 565525_567885
you made your confidence interval in part A ? 568205_570065
uhuh .
what did you get for a confidence interval in part A ? 570345_573045
&-um ten point two eight and thirteen point six four . 573285_576005
okay . 576105_576365
ten to about thirteen and a half right ? 578125_580325
yeah . 580765_581165
+, alright there's a range of what I would consider plausible potential values for mu one minus mu two hm ? 581035_589595
values that I think are likely to be mu one minus mu two at a ninety five percent confidence level +... 589935_595095
and what they're asking for is &~t for you to test the hypotheses just looking at that does it indicate to you there that it might be ten as a possible value just as +//. 595755_605235
to get a feel for what the answer might be ? 605475_607335
&-um yeah . 607695_608195
is ten reasonable ? 608215_608895
take a look at ten the value ten ? 609625_611085
yeah . 611365_612225
is ten inside that interval ? 612645_613525
yeah . 613665_613805
take a look . 614505_614845
no .
no . 614865_614945
&~w well yeah it is ten point two eight . 615985_617325
ten'd be .
oh ten oh no . 617565_618705
that's alright ⌈ that's alright ⌉ . 618825_619765
⌊ okay ⌋ .
ten is not a reasonable value according to the interval ⌈ right ⌉ ? 620705_623065
⌊ okay ⌋ .
+, okay so we probably are going to what end up rejecting or accepting ? 623745_626965
what do we think ? 627225_627905
rejecting .
probably rejecting .
rejecting .
all it requires us to is to adjust our test statistic a little bit . 628405_633365
you're gonna calculate or you already have calculated x@l bar and y@l bar but you wanna now see whether that difference in the sample means is significantly different from ten okay ? 634065_644085
significantly higher than ten so you're gonna subtract off ten instead of subtracting off zero . 644765_648325
oh .
+, and then still divide by that standard error that's your test statistic now . 649545_654065
and you do the test the same way you would with any other two observed test statistics . 655325_658865
its degrees of freedom will be the thirteen degrees of freedom and you've done the test so you just adjust what you subtract off as the hypothesized value . 660205_669585
so to just say that because ten's not in the ninety nine percent confidence interval that's not enough to say that ⌈ it's not ⌉ ? 670505_677625
⌊ not quite ⌋ .
yeah I wanted to look at our interval just to get a feel . 678145_680385
the thing is there's two things that are not quite right here to be able to do that and be our answer alone . 680985_685285
that is that the confidence interval when mu made was ninety five percent and they want you to do the test at a one percent . 686035_690735
so those are different right there and your &~ai your part B test is not a two sided test . 691275_696895
your h@l one your alternative is trying to say whether mu one minus mu two is more than ten so you're looking for a direction and you can't test a confidence interval confidence intervals are two sided . 697855_706735
there are such things as one sided confidence intervals but we don't go through those in this class anyway . 707615_711975
so you really do need to perform the test . 712865_714745
the test is performed though by just adjusting your test statistic and subtracting off ten when you compute it and then still doing it as a t@l test that is upper tailed with an alpha level of point o@l one . 715885_727745
for the +//. 728125_728365
for that t@l one you would hafta have the standard deviation divided by N minus one with that one ? 728885_734165
the standard deviations will always have an N minus one in them . 734345_737265
when you +//. 737685_737805
but you are given the standard deviations already computed for you . 738085_740725
take a look at page four twenty +/. 741275_742735
mhm .
+, you don't hafta do anything with N minus one as far as calculating (be)cause the s@l-s are given to you . 744875_750215
so you just square (th)em and add (th)em ? 750495_751875
so yep you wanna do the same thing for how you do a t@l test here you have to get your SP +... 751915_755215
you have to get your SP and then have one over n@l one plus one over n@l two . 756335_760735
so you have to get SP from your two s@l-s for that formula for combining the two . 761955_767175
the SP would be the s@l one minus s@l two ? 767625_770125
nope SP has the formula and it's a pretty complicated one but it's about averaging or pooling we wanna take a look at page +... 770645_780405
you have to take the square of ⌈ that ⌉ ? 782225_783585
⌊ yes ⌋ you have to square each of them you weight (th)em by the degrees of freedom the formula's on the top of page four fifty . 783625_788445
for the actual formula for finding your pooled weighted average estimate +... 788645_793825
page five +//. 797115_797695
<four fifty> four fifty . 798035_798995
oh four fifty . 799275_799675
yep .
that's your formula and you know what I really +//. 801155_802675
as I mentioned in the lecture pull out your formula sheet start working with your homework with a formula sheet then you don't hafta flip pages you've got it right next to you and you start really feeling comfortable with the way the formulas are presented there for your exam for next week . 802915_814075
they're all all the formulas are there you're not gonna hafta memorize any formulas all we don't do is we don't put a scenario in there and calculate the T for you and then write out the conclusion and everything . 814535_824475
so that's why I want you to understand the process but then have the ability to use the formulas that they've provided . 824825_829485
and so this one at the top S +//. 830825_832745
is your SP and then you've gotta multiply that by the square root of . 833105_836445
one over ⌈ n@l one ⌉ . 837045_837765
⌊ one over ⌋ okay . 838345_838365
that's the small sample T two sample t@l test the two independent samples the only adjustment we hadta do in two thirteen is that we hadta subtract off the ten instead of really subtracting off just zero . 838505_850345
(be)cause +/.
okay +/.
+, we were looking for a difference of ten or more . 852045_853925
mhm .
I just wanted to ask &-um I'm +//. 855845_857965
I still get confused between &-um independent <in B> and paired . 858325_861865
paired ?
⌈ yeah me too ⌉ .
⌊ mhm ⌋ +/.
yeah like for two nineteen +/. 862325_864225
mhm +/.
+, <it gives us> &-um it says that they did a comparative study on measurements of &{l=SIC absorbic@n$adj &}l=SIC &-um capacities and recorded for a group of twenty natives whatever and ten US +/. 864685_875785
+, mhm +/.
+, Bolanders .
so how do we like differentiate I don't know ? 876665_878925
oh there's a couple &~give giveaways that will tell you what to do without even thinking hardly at all right ? 879185_883725
basically every study is trying to compare two groups and yes they're trying to make the groups somewhat comparable with the &~ex exception of a difference in you know &~s one aspect and seeing whether that aspect is significant or not . 884885_896465
the thing is did they directly match and pair one to one <one from this group and> one from this group and put (th)em together or are they really just two separate groups . 897045_905105
when your sample sizes which are here ten and twenty . 906345_908565
twenty &-um Peruvian natives and &~twe ten US subjects you can't have pairing . 909165_916365
there's no way you could have paired twenty over here with ten over here . 916845_919645
okay .
so there is a ten group of ten and an independent group of twenty that I'm comparing overall . 920385_924625
okay +..?
⌈ versus +//. 925475_928775
⌊ so ⌋ +/.
+, lemme and +//. 928955_929255
versus +... 929955_930015
even if your sample size is the same for example two point two three on page four twenty three is about six rats &~an that received a growth hormone and six control rats . 930615_940295
there's six and six . 940875_941675
could there be pairing there ? 942175_943155
not because of the way they gave you the summary data the only way you can do a paired design a paired t@l test would be that you have the ability to either calculate the differences or you have the differences to work from . 943455_957795
so you can get d@l bar and you can get the standard deviation for the differences . 958375_962535
when you just have not the six observations for each group but the summary of x@l bar y@l bar those two standard deviations you can't get differences from there you can't get SD from there you couldn't do it as a paired test . 963305_976285
with this setup . 977405_978165
and these are the two classic ways of giving data . 978805_980585
summarizing by giving the mean$n and standard deviation already for you or in the case when it is paired as in section four setting it up so you have person or pair or household or farm number one . 981325_995585
and there are the two responses for it . 996465_998505
they always add another row to tell you what pairing number it is . 999425_1003145
they make them link together . 1004525_1005565
if you have data laid out and you say look at those first two is there something they have in common ? 1006545_1011665
do they have to go together ? 1011845_1012965
they both came from person number one they hafta be compared to each_other . 1014005_1017145
they hafta be a paired observation . 1017685_1018925
versus if I had ten people here and ten people here in two different teaching methods that first person over here doesn't hafta necessarily be paired up with this first person over here they just were two separate groups taught with two different methods that I'm comparing as a whole . 1020165_1031645
overall .
I didn't match them by gender or by pretest score or anything else I just +//. 1033125_1037445
I'm looking at the two test &~s scores for the two teaching methods overall . 1038285_1041205
but a_lot_of times the way the data's presented should indicate the idea along with a description of_course of the problem . 1041865_1048485
okay ? 1049665_1050045
if the sample sizes are not equal it can't be paired . 1050445_1052505
if all you have are just two means and two standard deviations for these two groups whether they're the same sample size or not it can't be paired . 1052965_1060985
you can't analyze it as a paired situation . 1061225_1063305
if you have the actual data as in even two point two one and it's listed out there and they look like they're the same number of observations it doesn't guarantee it's gonna be paired . 1064825_1074545
you have to still take a look at the description . 1074885_1076725
so in that example that would be independent . 1077785_1079545
yep what it +//. 1080265_1080805
basically they'd said twenty workers were included in the experiment of these ten were selected at random and trained with method one . 1081425_1088545
the remaining ten were trained with method two . 1089025_1090885
okay .
+, that at random means that those two groups are independent . 1091565_1093845
so that's how you can kind_of pick (th)em out if they're both laid out like that you can pick it out (be)cause &~w that it'll always specifies that at random if it's not paired . 1094725_1102345
⌈ and it'll always say paired ⌉ . 1102685_1102725
I mean &~that ⌊ that's how that independence ⌋ assumption is usually meant by saying that I took the people and randomly allocated them into two groups . 1102725_1108825
okay that's typically how it's done . 1109545_1111405
or at least I went to this population of US citizens and picked a sample at random of twenty and I went to this population of Peruvian people and picked &~s ten at random though they're still supposedly independent samples then . 1111965_1124645
okay that's how you distinguish between the two . 1125745_1127485
&-um on two point two three they ask for an explanation like in a sentence +/. 1128125_1131025
mhm +/.
+, how would you want it like +//. 1131465_1133245
&~wh what really was it looking for ? 1133785_1134725
two point two three ? 1135145_1135865
yeah . 1136085_1136345
+, do a test state the assumptions so &~the I mean there's . 1136705_1141285
and the assumptions are what ? 1141285_1142325
<the assumptions> the assumptions are going to be usually in the summary also . 1142405_1147625
the two basic components of any +//. 1148205_1150205
of all tests so far is that you've got random sample or samples . 1150445_1153185
and you've got normal distributions . 1153925_1154945
or you've got the large sample sizes so you get the normality . 1155845_1159485
but those are all the ideas but you still need to be able to say them correctly . 1159765_1162645
rather +//. 1163045_1163425
you can't just say what are the assumptions random sample normal no that's not enough you have to tell me what's a random sample what's normally distributed what are you talking about there so you need to be able to say it in a sentence . 1163465_1174025
alright ?
in terms of the actual assumptions section four page four thirty one paired design there's the assumptions right in that blue box . 1174785_1185465
so maybe when you're practicing for the exam and you get your &~f you have your formula sheet to study from maybe you write that out next to that on the formula sheet so every time you go to that to look at and do you remember that assumption with it . 1187185_1196725
but you have small sample inferences about the mean difference assume that the differences are a random sample from a normal distribution . 1197885_1203405
that's what you have as an underlying assumption for the paired t@l test for the confidence interval . 1204545_1209585
every confidence interval along with its test that go hand in hand have the same assumptions underlying them . 1210775_1215915
what's assumption again ? 1216235_1217555
assumption is what does the data hafta be in order for this inference procedure to work ? 1217855_1222055
you know we we talk about this ninety five percent confident and we say that means if you were to repeat it over and over ninety five percent of these intervals are gonna contain the right quantity well that only works if you really are taking random samples . 1222275_1234855
and you have normality to begin with (be)cause you're +//. 1235075_1237175
what are you doing in your you're using a t@l distribution which comes from the fact that that's what you should get when you sample from normal curves . 1237395_1243915
t@l curves for the test statistic . 1244495_1246035
so those assumptions only can help to some degree . 1246875_1248975
there's a little robustness . 1249495_1250555
for normal curve +//. 1250655_1251115
normal distribution you just say zero it was zero one ? 1251575_1253695
no it is actually normal with some mean difference and some standard deviation but you don't even have to write that notation you can just say from a normal distribution . 1253895_1260555
okay . 1260995_1261275
+, and that's adequate . 1261495_1262315
it's not +//. 1263455_1263935
your differences and your data's not gonna come from a normal zero one that would mean all your observations hafta be around zero . 1263885_1269825
no they come from some normal distribution that might be normal zero one . 1270405_1273305
so so the confidence interval again what you said was &-um if you're doing it over and over again say it's <ninety five percent> ninety five percent of the time this will be included in the interval or ⌈ what's ⌉ . 1274225_1284125
⌊ not the ⌋ &~inter don't interpret your confidence interval level with just one interval . 1284125_1288185
you should interpret it as being looking at many intervals . 1288925_1291425
it's wrong to say ninety five percent of the time the mean mu will be in this interval . 1293195_1297035
that is not correct . 1297775_1298575
okay .
+, (be)cause mu is either in that one interval or it's not . 1299355_1301595
+, mhm +/.
+, ninety five percent of the intervals made with this method if it were repeated are expected to contain mu . 1302635_1310455
I'm emphasizing the plural intervals +... 1311695_1313695
I can talk about the collection of possible intervals and what I expect for that collection . 1314695_1318915
I can't talk about every one interval (be)cause either it does or doesn't . 1319765_1323365
mkay they did have a pretty good picture back in chapter eight when they first introduced confidence intervals to kind_of remind you of that idea and I knew we kinda sketched the idea but it's page thirty twenty . 1325065_1336125
back thirty twenty +... 1336625_1337905
and the example six on page thirty twenty two are both good ones to maybe recap that idea again . 1339905_1346025
but see how every one interval either does contain the parameter +/. 1346305_1349805
+, mhm +/.
+, or it misses it . 1350865_1351545
+, mhm +/.
+, you're talking about the collection of intervals if you were to repeat it many times and we'd expect ninety five percent of them to be yes to be good ones . 1352585_1360125
the one that I got I don't have no idea which one it is . 1361165_1363325
mu which one it measures up to . 1363805_1364465
I don't know whether mu's in it or not but I know that the procedure is such that ninety five percent of the intervals +... 1364525_1370245
made with this method in repeated samples are expected to contain mu . 1371435_1375195
that's why I have confidence in the one I have . 1375995_1377835
that's how I can say it . 1378395_1379775
+, mkay .
+, alright ? 1380275_1380475
&-um I have sort_of a general question &~i what +//. 1381375_1384895
if you have a &~sma in the matching in the matched pair comparisons +/. 1385895_1389235
mhm +/.
+, if you have a small number then they give us all the formulas for the t@l test +/. 1389515_1393455
+, right .
+, ⌈ for everything ⌉ .
+, ⌊ right . 1393735_1393775
right ⌋ +/.
+, if you have a large number they only give us the &-um . 1394175_1398255
the t@l formula right ? 1398295_1399415
(0.4) .
yeah . 1400705_1401305
you can always do it as a t@l test . 1402725_1404805
or no that would be a Z . 1405005_1405785
wouldn't ⌈ that be ⌉ ? 1406225_1406505
⌊ but you ⌋ could +//. 1406505_1406965
and you can still call it a t@l statistic if your sample size is large though you're just gonna be farther down on that t@l table . 1407245_1412325
⌈ in terms of percent ⌉ . 1412785_1413365
⌊ and you're using it ⌋ and you're using it ⌈ different . 1413705_1414365
the Z ⌉ .
⌊ you're using the Z ⌋ basically anyway . 1414465_1415985
so you can call it a Z if you wish but you don't even have to keep it a T do it with the sixty degrees of freedom and it really is a t@l test +/. 1416425_1423405
⌈ but what &~i ⌉ +/.
+, ⌊ but it's ⌋ it's so close to &~n a normal zero one that you're basically doing the same thing . 1423785_1427225
what if you wanted to find a confidence interval though for something large ? 1427495_1430415
well again you would basically can use the z@l alpha over two number in there instead of the T one . 1430615_1434595
so it's all the same formulas . 1435835_1436995
mhm it's the same formulas though just T versus E . 1437435_1439715
mhm .
if you always do it as a t@l test which is by the way the pair design is presented . 1440675_1445255
it doesn't present a Z version of it really you will always be correct . 1445675_1449175
it's just that when you get to degrees of freedom on your t@l table +/. 1449515_1451455
mhm +/.
+, where are you gonna be ? 1451915_1452355
way down at the bottom . 1452475_1453235
possibly even at the very end +/. 1453595_1454855
+, mhm +/.
+, which is your z@l percentiles anyway IE you're doing it as a z@l test . 1455405_1458705
+, mhm +/.
+, okay ?
so it's +//. 1460265_1461145
everything's +//. 1461565_1461725
it +//.
this this is not how it was for the ⌈ independent of A ⌉ +/. 1462005_1464965
⌊ right they give you both versions ⌋ . 1464965_1465905
+, so if it's large we do the &-um the t@l test +/. 1466105_1469845
+, mhm +/.
+, only when we +//. 1470025_1470685
it it comes onto alpha we're looking it up on the z@l table . 1470905_1473065
yeah or you can look it up on the t@l table the very last ⌈ column or row ⌉ +/. 1473165_1476085
⌊ mhm ⌋ +/.
+, with the &~alph &-uh infinity degrees of freedom is your z@l percentiles . 1476325_1478725
that is what that is there your computer output doesn't say T versus Z . 1479635_1484495
it just does it always as a t@l test . 1484835_1486255
no matter what the sample sizes are . 1486875_1488175
and it has ability to have actually t@l distributions with a hundred degrees of freedom or three hundred degrees of freedom (be)cause it can do it that way so it's very precise . 1488935_1495735
+, okay .
+, it's just that if you were doing it by yourself and it was thirty hundred degrees of freedom your answer as a z@l test wouldn't be hardly any different from their answer calling it a T . 1496135_1504235
and doing it that way . 1504675_1505295
okay ? 1506035_1506355
over here . 1506835_1507335
yeah &-um on two dash two +//. 1507515_1509455
two point two three ? 1509935_1510315
mhm .
I like set everything up like I set up the &-uh T ? 1510455_1515695
mhm .
+, like tested x@l bar over y@l bar over square root it's two one through n@l one plus ⌈ SU two over n@l two is that ⌉ . 1516035_1526075
⌊ did we do that one ⌋ ?
⌈ this one ⌉ . 1526075_1526535
you you +//.
do I need &~i is +//. 1527475_1529315
okay +/.
yep mhm .
+, what do I compare that to then ? 1529735_1531295
what's statistic test like .
what's your degrees of freedom here going to be ? 1531835_1534555
is it five ? 1536885_1536965
it's gonna be five degrees ? 1537525_1538425
okay which one . 1539385_1540045
I didn't do the t@l test . 1540325_1541205
⌊ there's two T here ⌋ . 1541825_1541945
⌈ &-uh you &~sh <do you> &~no do you ⌉ not need to do one or you just . 1541945_1544105
⌊ &~well ⌋ .
⌈ I did ⌉ the other formulas &-um . 1544485_1546065
right you want +//. 1546165_1546745
I'm looking at the solution here and the solution here has it doing it with that t@l star that we did not cover . 1547645_1551705
why are they doing it with this t@l star version ? 1552065_1554865
right &~y &~y &~y yeah . 1554885_1555185
+, okay because look at those two sample standard deviations there two point two three . 1555305_1559525
fifty seven and sixteen right are your two sample standard deviations ? 1560385_1564505
wait . 1565515_1565755
no .
⌊ is that what you got ⌋ ? 1566435_1566915
⌈ no they're not ⌉ .
seven point six ?
two point two three ? 1568155_1568815
seven ⌊ point ⌋ six .
⌈ seven ⌉ .
sixteen point four .
you got &~sixt what did I say ? 1569295_1574355
fifty seven and sixteen ? 1574535_1576195
is what I have written down here now and again I haven't checked these answers (0.4) two point two three yeah oh seven duh that's wrong . 1577075_1587195
alright but anyway &~wh there are some informal tests that you could say are these two sample standard deviations comparable enough ? 1588195_1595955
mm .
+, the thing is here we are not doing the t@l star version we're not going further and going through that (be)cause the degrees of freedom do get to be a little strange or you take the minimum of the two +/. 1596915_1605035
+, right .
+, and so on so you can just treat this as a regular t@l problem . 1605535_1609155
however you're still going to pool those two now &~d does it say . 1610075_1613955
will you +/. 1615575_1615815
yep .
+, will you like go through that and do this one I couldn't . 1615885_1618165
it's gonna be done just like you have &~two nine just like you did two nineteen . 1618645_1622445
or just like you did two twenty . 1622745_1624205
in terms of what test statistic you should use here +... 1624665_1627065
two nineteen and two twenty have the the one that we just wrote out a a minute ago too so I'm gonna advocate that you should still take the forty one and the sixty and subtract it and the denominator should have the one over six and one over six with the SP . 1629325_1643425
down there . 1644075_1644555
so you wanna pool the two s@l-s and get an SP and use that to get your test statistic and your degrees of freedom here would be ten degrees of freedom . 1645115_1653515
six plus six minus two . 1654415_1655875
then what do you compare that to like what is entered like . 1658135_1660295
and then you're gonna go to ten degrees of freedom for your t@l distribution and find its p@l value or find a cutoff value depending on +//. 1660335_1668095
it's a lower tailed test +/. 1668195_1668975
mm .
+, so I would find its p@l value and compare that to this is one that doesn't have an alpha it doesn't have the alpha . 1669825_1674925
if we did it the other way already on that I mean will you count that as pass ? 1675185_1677925
yeah I'm gonna make a note to the GSIs +/. 1677925_1679585
alright .
+, (be)cause I'd I +//. 1679745_1680485
had I saw seen that that one was assigned (be)cause I didn't assign these questions I might not have had that in there . 1680625_1684165
what's what's the alpha like what do you take on the alpha ? 1684345_1686105
take an alpha of point o@l five if it's not given and make your decision <that way> that way I know you can make the decision if alpha were given at any particular level and that would be fine . 1686265_1693885
when is it appropriate to use s@l pooled and when is it not ? 1694515_1698615
the only two cases we have here is when you you have large samples you don't hafta pool and you do it as a z@l test . 1699095_1704775
if your sample sizes are small then we're gonna add the assumption of common population variants and pool . 1705715_1711075
and do it as a t@l test . 1711695_1712555
those are the two main roads that we're &~try taking here . 1713415_1716555
so it should +//. 1717015_1717635
if it's not a large sample it always needs to be s@l pooled . 1717835_1719955
yep mhm . 1720135_1721055
and then if it is a ⌊ large ⌋ +/. 1721135_1721855
⌈ but what if ⌉ +/.
+, population then it's just the &~S the ⌊ standard deviation ⌋ +/. 1721845_1724865
+, ⌈ squared ⌉ +/.
+, over ⌊ the ends ⌋ . 1725425_1726105
⌈ over ⌉ the ends mhm . 1726105_1726525
so small is pooled ? 1727185_1728605
small is ⌊ pooled ⌋ . 1728745_1729125
⌈ what exactly ⌉ do you do wi don't understand really what you said what you do with the pooled ⌊ what ⌋ ? 1729145_1732425
⌈ the pooling ⌉ is just saying +//. 1732945_1734105
see you +//. 1734525_1735085
if you don't pool and you have small sample sizes then that T that you're really computing is not gonna have exactly a t@l distribution . 1735285_1741485
its distribution is not a t@l distribution but you can approximate it being conservative and it goes through this whole technique with this t@l star . 1742045_1748185
which works and you can still do a good test that way . 1748455_1750855
but rather than going through all that subtlety we have just said let's still assume common variants . 1751495_1755975
&~y your test is pretty robust against that assumption meaning even if the variances weren't that &~cl real good you'd still be okay to do it as a t@l test . 1756695_1763755
so we're just gonna be saying let's assume that the two variabilities in the two populations are the same for the responses and so our two s@l-s are both estimating that we pool (th)em together to get a good estimate overall . 1764275_1774695
so that's like how we just did six plus six is twelve minus two ? 1774705_1777145
yep ⌊ mhm ⌋ . 1777365_1779025
⌈ alright ⌉ .
+, mhm +...
for the degrees of freedom . 1779565_1781265
for two point two three was the &-um alternative hypothesis what was the alternative hypothesis ? 1782425_1788685
can you say that again thirty point what ? 1789145_1790405
the one we just did two point two three . 1790705_1791985
two point two three ⌊ was the ⌋ . 1792445_1795205
⌈ is that an ⌉ upper tailed ? 1795325_1796025
it &~depen no lower tailed +/. 1796825_1797985
oh okay +/.
+, one sided lower tailed it depends though again what you call control and &~ho hormone group one or group two typically the rule is to use the first one listed there as being group one . 1798345_1806265
and the second one being group two but if you identify it differently just say so . 1806665_1810005
so that we know how you're calculating your quantities . 1810785_1812585
+, okay . 1813265_1813365
+, and you want to say that the weight gain is higher if they received the hormone so I'd want the group two to be higher group one to be lower . 1814125_1820765
+, mhm .
+, so one minus two should be low negative . 1821545_1824665
+, right +/.
+, that's why it's a lower tailed test in thinking that through . 1825045_1827905
for four point thirteen +/. 1829185_1830265
mhm .
+, can you &-um explain part B ?
mhm I was gonna ask that too .
four thirteen ? 1832325_1834585
yeah . 1834805_1835045
(0.4) .
okay mhm +... 1838045_1839385
there's the little bit about making your design even a little better by making sure you do some randomization . 1842285_1847465
this is a paired design right ? 1848105_1849345
(be)cause we're pairing up these plots by farm +... 1850205_1853825
but even in a paired design there should be some randomization perhaps . 1854165_1858685
if it's possible . 1859065_1859605
especially when you have two items &~th that are paired and one of (th)em is supposed to get one treatment and the other is supposed to get the other but they're gonna be compared as a pair which of those two items gets which treatment should be randomized . 1860645_1871125
that's the idea . 1872145_1872765
so that you won't always have +//. 1873125_1874225
you know if if your &~f farm was always set up to have a top plot and a small +//. 1874725_1877585
and a lower plot a north and a south one don't always give the north plot strain A and all the south strain B (be)cause you might have that be confounding . 1877655_1885375
that might be something that says the water all drained from north to south so the south ones didn't do well because of the drainage problem . 1885715_1892615
and then that would +//. 1893175_1893575
you wouldn't know whether or not strain B didn't do well because of drainage or whether they didn't do well because of being strain B . 1894195_1900275
so you randomize . 1900855_1901995
so that's the idea we want you to get in there . 1902955_1904635
how can you randomize ? 1905835_1906835
here's farm or farm number one here are the two plots &~s plot one plot two flip a coin . 1907055_1913355
if it's a heads plot one gets A if it's a tails plot two gets A . 1914455_1917815
and that's how you can make the assignment . 1918495_1919615
(0.4) that's one way doing it anyway and there's a couple other questions like that right where you have to kind_of think through ? 1921735_1930935
(0.4) .
can &~yo can you tell me the answer for four point eleven ? 1935475_1937155
(0.5) .
okay did you get your standard deviation ? 1937915_1943355
what did you get for your ⌊ SD ⌋ ? 1944615_1945435
⌈ &-um ⌉ two point six one . 1945435_1946375
that's much better . 1946535_1947275
and what did you get for your t@l statistic ? 1948115_1949035
four point five nine . 1949435_1950455
that's a little better too mhm . 1950575_1951955
so I reject . 1952195_1952895
and you reject . 1953255_1953935
okay . 1954175_1954435
&-uh what did you get for your t@l statistic ? 1954755_1957695
four point five nine . 1958375_1959375
four point five +//. 1959495_1960015
<no no> no no no . 1960075_1960755
not quite .
I had +//. 1961135_1962295
my d@l bar was one point thirty three +... 1963905_1965965
what's &~o what should be on the bottom here ? 1968165_1969125
oh square root of N . 1969805_1970645
thanks . 1971245_1971545
yep . 1971665_1972125
&-um I was confused about how to do four point one four +/. 1972985_1977525
yeah me too +/. 1978685_1979805
+, &-um first I was confused about whether or not it was paired (be)cause they made it seem like +/. 1980225_1984865
+, right . 1985105_1985405
+, &~i I ⌊ don't know ⌋ .
⌈ if you read ⌉ the whole problem or actually get to part C and read that part C also it tells you that what they're doing here is they're taking the same data and it really was paired +/. 1986225_1997285
mhm .
+, and they're saying let's pretend that data came from a situation where it was not paired . 1998125_2001425
so you're not using the information of putting this one with this one and comparing it directly . 2001805_2005645
+, mhm .
+, you're just comparing the two groups completely as a whole independently . 2006005_2008945
and it turns out that in four thirteen you say you would reject h@l naught . 2010025_2015625
strain A is significantly higher than strain B . 2015965_2019045
+, mhm .
+, yet when you do it as an independent samples design not using that pairing aspect +... 2020125_2024525
you end up accepting h@l naught . 2025605_2028025
if you analyze it with the SP and the t@l statistic for independent samples you're doing the t@l test for independent samples here . 2029285_2036245
what did you get to be the rejection zone in +/. 2038805_2042105
in &~wh +/.
+, four point one three ? 2042485_2043025
in one three ? 2043365_2044045
yeah +/.
+, mm they have one point eight nine five reject if it's more than that seven degrees of freedom upper five percent +... 2044405_2054685
and so the idea here that they're getting at is that the calculations +//. 2055105_2063045
the data were the same . 2063545_2064205
however the standard errors get to be different because you didn't use the pairing aspect you didn't work with differences . 2065235_2070675
the reduction in variability helps to make the pair design better . 2071595_2076835
I've got a bunch of observations over here and they vary . 2077935_2079735
and here's another bunch of observations and they vary too . 2080595_2082635
now part of the reason why they vary is because they came from different farms . 2083915_2086575
but these came from the same set of farms so I should put them together so that I compare an apple to an apple and look at that difference due to the treatment alone the same two plots from the same farm . 2087345_2098285
and I'm using that extra information . 2099045_2100525
so that if this +//. 2101225_2102185
if this farm +//. 2102205_2102525
if one farm was unusually high it would probably unusually high for both strain A and strain B . 2102665_2107805
but the difference then the gain in the difference of those two strains would be masked coming out directly . 2108505_2113725
versus if you just kept (th)em as two independent sets a very large observation here does not get directly compared with a very large one here . 2114545_2121165
and even though +//. 2122045_2122445
and that +//. 2122665_2122825
you aren't using that aspect you're not reducing variability due to +//. 2123125_2126505
from farm to farm by pairing (th)em . 2126885_2128445
reducing variability is usually always good . 2129285_2131245
(be)cause that means you're then +//. 2131565_2133125
you're gonna able to compare things more accurately and see if there's a difference or not . 2133285_2136685
so by pairing you reduce the variability from farm to farm by comparing directly and you were able to see the significant difference in these two strains . 2137705_2146065
whereas that variability among the farms not comparing them with pairs masked out the actual increase in strain A over &~ba strain B . 2146825_2156625
and so you didn't see it when you &~did treated it as independent samples . 2157585_2160885
okay one of the pros and cons section they mentioned about pairing helps to reduce variability in responses (be)cause you're comparing one item that is very like to the other the only difference is the treatment so you're getting a better idea of what the treatment effect really is . 2162155_2175235
whereas it's harder to measure it if you've got independent samples because there's other things that are affecting those things . 2176815_2181495
over there . 2182235_2191975
what what's the t@l value for two point one five ? 2183215_2186935
(0.4) .
two point one five +..?
two point one five was assigned ? 2189595_2195355
no . 2196535_2196935
no .
what did I do ?
two point one three ? 2199835_2203555
and two point one nine +... 2203895_2206875
alright . 2210855_2213035
how did you +//. 2212165_2212965
I don't know if you just said this &-um for four point one three +/. 2213285_2216445
mhm .
+, to set up your &-um null hypothesis and alternate hypothenis hypothesis +/. 2217465_2221925
+, mhm .
+, &-um and it's a one tailed test but it +//. 2222745_2227225
would you still set it up as S equal to zero and then S greater than ⌊ zero ⌋ ? 2227845_2234385
⌈ zero ⌉ .
mhm mhm ⌊ that's if ⌋ . 2234685_2235785
⌈ you wouldn't ⌉ do like S plus +//. 2235785_2237385
S &~minu s@l one minus +//. 2239145_2240385
⌊ you know what I'm saying ⌋ ?
⌈ that delta ⌉ when you're saying S you mean that delta thing . 2241185_2243645
⌊ right ⌋ ?
⌈ uhuh ⌉ +/.
+, okay ?
and that is really the difference in the means . 2244705_2246965
+, oh .
+, okay ? 2247325_2247885
the mean$n of the differences is the difference in the means$n . 2249125_2252005
what I mean there is +/. 2252005_2253125
+, oh I see .
+, if you had taken and calculated the ⌊ differences ⌋ +/. 2253885_2256565
+, ⌈ mhm ⌉ .
+, for each farm and averaged those +/. 2256885_2258525
+, mhm .
+, that's called d@l bar . 2258665_2259805
⌊ right ⌋ ?
+, ⌈ right ⌉ .
+, that's representing what you think is the mean$n of the differences . 2260205_2264085
+, mhm .
+, if you calculated the average of the first group x@l bar and calculated the average of the second group y@l bar . 2264375_2271955
those are the means ⌊ separately ⌋ +/. 2272855_2275415
+, ⌈ mhm ⌉ .
+, and if you take the difference of those means you get back d@l bar . 2275675_2279235
+, okay .
+, okay ? 2279815_2280035
so this symbol is reserved to represent that we're in a paired situation ⌊ and ⌋ +/. 2280215_2285575
+, ⌈ mhm ⌉ .
+, it represents the mean difference . 2285695_2287595
okay . 2287755_2287935
so how do you know whether you wanna put greater than or less than zero ? 2288655_2292835
depends on how you calculate your differences +... 2292935_2294775
in general you're gonna calculate just going down . 2295835_2298275
mhm .
+, A minus B +/. 2298755_2299415
+, right . 2299755_2299815
+, if difference is defined to be A minus ⌊ B ⌋ +/. 2299955_2302515
+, ⌈ mhm ⌉ .
+, then the mean$n of my difference is I generally want to see them being positive ⌊ to show ⌋ +/. 2303375_2308055
+, ⌈ okay ⌉ .
+, that A's bigger than B ⌊ on average ⌋ . 2308255_2310295
+, ⌈ okay ⌉ .
+, so just ⌊ think that ⌋ +/. 2310475_2311135
+, ⌈ got it ⌉ .
+, through mhm .
for seven point two three &-um ⌊ can I just go over that one ⌋ . 2311835_2315135
⌈ &~seven two ⌉ three . 2315135_2315495
for A you would test A as being independent right ? 2316875_2321475
and then . 2321475_2322375
yeah I couldn't ⌊ tell for this ⌋ . 2322395_2324235
⌈ B is just ⌉ .
right well take a look again . 2325135_2326475
okay . 2326775_2327075
+, you have +//. 2327435_2328415
you're looking at two different routes &~i five drivers were randomly selected from a group of ten and assigned to route A . 2329075_2335195
and then the other five were given B so is that way of selecting or assignment gonna indicate paired or independent ? 2335475_2342575
independent . 2342955_2343895
independent mhm I had ten altogether I just randomly picked five I didn't take the ten drivers and kind of analyze their driving habits and try to put two together as a pair to say these guys are both are <a little> a little fast on the throttle or whatever you know they didn't try to match (th)em they just picked five and assigned them to one group . 2344805_2359545
so that's how <they're doing it> they're doing it as an independent samples design . 2360185_2362625
small sample sizes so we'll have to get SP and calculate the test statistic that way an alternative design for the study would be though to make the comparison more equivalent by doing some kind of pairing . 2363525_2372665
okay .
+, how would you &~compa pair (th)em maybe by driving habits how many accidents they had that might indicate whether they're a reckless driver or not and you put (th)em together by whether they're reckless or not reckless something like that . 2373275_2385115
whenever you can make the drivers that's one way what would be another way ⌊ that would even be better ⌋ ? 2385875_2390775
⌈ couldn't you take ⌉ &-um the ten drivers and you have h@l one driver A h@l one driver ⌊ B ⌋ ? 2390795_2394615
⌈ perfect ⌉ exactly . 2394635_2395775
mhm .
if you have the same person driving both routes then you have that same characteristics in the driver affecting both answers and the differences would be due to the routes perhaps more . 2397205_2405985
than just the driver differences . 2406465_2407505
very good .
on two point one nine the t@l value would that be twenty point one ? 2407945_2414445
mhm +...
two point one nine is &-um you're not calculating a test statistic here but you're doing a confidence interval . 2416245_2420365
yeah well don't you have to calculate the &~st test statistics to get the confidence interval ? 2420785_2423865
no not +//. 2424045_2424385
but &~y the confidence interval can be constructed by taking this difference plus or minus a_couple_of these and you forgot to put your SP on here okay ? 2424825_2433725
mhm .
so look at +//. 2435945_2436405
again start getting your formula sheet out so you can . 2436805_2438945
I don't know where is that formula sheet when did you give it to us ? 2439265_2440925
do you have your packet from your &~exa old exams and the confidence intervals ? 2440945_2444605
no excuse_me the computer modules ? 2445325_2446845
⌊ it's in the back ⌋ .
⌈ is it in the ⌉ back of that big packet we have ? 2447665_2449725
⌊ I keep mixing it in with my papers ⌋ .
the gold packet . 2449825_2450305
mhm it is back there and it's also on the web if you wanna go on there and +/. 2450685_2454765
⌈ okay ⌉ .
+, ⌊ print it ⌋ from there you can . 2454965_2455605
okay it's on the web +/. 2455905_2456605
mhm .
+, and it's just called the . 2456745_2457645
&-um it's under all the course info and I think it says formula sheets . 2457785_2461705
okay .
mhm you ⌈ can print out a ⌉ copy .
⌊ that's probably ⌋ a_lot more helpful .
mhm mhm okay . 2462305_2466285
how do you put into the calculator what would be . 2466705_2470305
okay how +//. 2470405_2471205
I mean for calculators +... 2471345_2472305
you have the ability to enter data . 2472725_2475405
does anyone else have a TI that they maybe want a little more review of at all ? 2475875_2478955
do you have a TI ? 2479355_2479955
I have an eighty two . 2480275_2480875
you have an eighty two ? 2480955_2481535
yeah . 2481755_2482115
yep have you +//. 2482195_2482535
do you know how to put data in &~an . 2482735_2483715
in a list ? 2484355_2484655
in a list ⌈ and ⌉ +/. 2484795_2485515
⌊ yeah ⌋ +/.
+, do all that ? 2485715_2485975
were you in one hundred or not ? 2486575_2488915
no that's where we did it all too +... 2489035_2490335
in the eighty five you also have the ability and it's all under the stat button . 2492315_2496535
+, okay +/. 2496755_2497355
+, mkay ?
and under stat you have calculating things and editing things . 2498015_2501035
+, uhuh .
+, so under edit it says okay you're gonna edit two possible lists or just one all you do is just keep those names and hit enter enter and you've already got some data there . 2501625_2510265
+, ⌈ mhm ⌉ .
+, ⌊ okay ⌋ you can enter your listing of your differences and put them in under all the x@l-s . 2511045_2517445
wait listing of &~i . 2517805_2518345
let's suppose you had your differences like these +... 2518565_2521965
&-um suppose you wanted to get the average of these five numbers . 2524165_2527065
okay .
+, okay so you can type in your eighteen your twenty four I'm putting them in as x@l-s I'm putting on the thirty . 2527845_2536945
you're skipping are you skipping ⌈ the Y ⌉ ? 2537845_2539225
⌊ skipping the y@l-s ⌋ for now +/. 2539225_2540245
okay .
+, mhm twenty one and then a thirty two . 2540805_2544625
how do you skip do you just push PM ? 2544845_2546325
yeah just down . 2546465_2547045
⌈ okay ⌉ ?
⌊ okay ⌋ .
+, once they're entered <and if I> go further I'll see that there's nothing left after that so I've just got those numbers . 2547845_2551785
+, okay .
+, then I can go back out you can go back to calculate so I'm gonna go back to stat calculate and there's +//. 2552435_2558855
there I'm getting the same two names those are the ones I wanna work with one bar . 2559595_2562695
I push one bar there's your x@l bar and there's your standard deviation . 2563015_2568695
+, ⌈ okay ⌉ . 2568975_2569335
+, ⌊ okay ⌋ ?
pretty nice right ? 2570655_2571475
yeah . 2571715_2571955
when you go back to stat &-um <hm hm> hm hm hm +... 2572315_2577095
there is +... 2579115_2579595
there's insert sort there's clear . 2581595_2584075
see the clear ⌈ X and Y ⌉ ? 2584355_2585235
⌊ mhm ⌋ .
+, that's how you wanna press to get (th)em all back to nothing there so you can enter data at the start . 2585575_2588915
wait can I write +/.
mhm +/.
+, I'll write this down .
basically it's under stat and edit and stat and calc . 2589255_2592915
okay . 2593375_2593495
thanks .
⌈ so I'm looking at those two ⌉ . 2593855_2594595
⌊ can you show me real quick ⌋ . 2594615_2594895
mhm .
when you guys have it the same eighty twos you wanna go under stat and also do it under edit so press edit under stat and you should have a listings there . 2595275_2605695
l@l one ⌈ l@l two l@l three ⌉ . 2606275_2606995
⌊ mhm mhm ⌋ .
+, pick one of those doesn't matter which one you wanna do and put your numbers in them . 2607675_2611055
&-uh like just for the x@l-s ? 2611515_2612715
just for the x@l-s or if you have two sets put one in one and one in the other and you can analyze both of (th)em but one at a time . 2612775_2617795
okay .
+, okay ?
so you put in some data maybe you wanna put in your strain a@l-s or your differences if that's what +//. 2618975_2623775
if you've calculated your differences . 2623855_2624975
I already +//. 2625615_2625895
okay +/. 2626255_2626535
+, &~w what am I trying to find out here ? 2626715_2628195
this is a pair design if it's a pair design you can enter your differences . 2628535_2631075
mhm .
+, and if you put those in one of your lists you can have the list do your x@l bar and your . 2631745_2637065
wait it's under stat &~i &~i &~we I went to okay . 2637145_2639825
here's stat .
mhm then you always have to hit enter enter to just say yes those are the two variable names . 2640305_2644565
oh +/.
+, or just down down yeah there you go and now you can enter data . 2644785_2647625
then what do you do ? 2647965_2648605
if you just fill in &~L ⌈ L ⌉ . 2648945_2650285
⌊ if ⌋ you fill in your numbers +/. 2650365_2651665
mhm .
+, then you wanna go back to stat and go over to calculate and say I wanna calculate some things . 2652225_2657005
+, mhm .
+, the main thing that you wanna do is one bar so go over to calculate . 2657985_2661585
how do I .
the &~ef left and right arrows will get you moving back and forth and there's one variable statistics and then you specify at the end of that either l@l one or whatever column it's in it will automatically do it on l@l one if you don't tell it +/. 2662285_2675485
mhm .
+, otherwise you hafta have one bar and then put second function . 2676185_2678225
+, mhm .
+, and put in that one .
how do you make it skip ? 2678845_2679785
like I can't make it skip . 2679985_2680965
just go down . 2680985_2681485
it doesn't . 2681765_2682165
oh because you cleared out the one already it it only +//. 2683425_2686145
always just needs to be the one there to hold a place but it doesn't hafta be a number . 2686705_2689805
that's part of your data . 2690485_2691185
you wanna always enter x@l-s . 2691825_2693045
&~i if if I'm doing one list I'll always enter the x@l-s and then +/. 2693725_2696845
just yep mhm . 2696845_2697425
+, and then I go . 2697465_2698005
mhm ⌈ then down ⌉ .
⌊ then just down ⌋ .
yep there you go . 2698725_2702025
oh ⌈ okay ⌉ . 2702105_2702725
⌊ so ⌋ +/.
mhm .
+, what is this doing here ? 2702985_2703765
now what that says is that you're gonna call up to do &~s summary measures +/. 2703785_2706425
mhm .
+, if you want it on l@l one you can just hit enter . 2706685_2709005
+, mhm .
+, if you want it on l@l two or something else you have to do second function and specify l@l two behind it . 2709245_2713845
+, oh .
+, you can put in l@l one just to show you what that looks like and that's what it should look like depending on which column you have . 2714465_2718805
okay ⌈ then just hit enter ⌉ ? 2718965_2720005
⌊ hit enter ⌋ and it will give you x@l bar and give you S . 2720225_2723185
wow . 2723585_2723905
+, right there for you . 2724165_2724945
⌈ okay ⌉ ? 2725465_2725725
+, ⌊ neat .
okay ⌋ .
+, ⌈ you don't hafta do all that calculation by hand ⌉ . 2726325_2727785
wait I I just +//. 2727905_2728265
I lost it again . 2728785_2729185
⌊ mhm ⌋ .
⌈ like ⌉ okay I don't even know where I am anymore . 2729245_2731285
okay there stat enter enter . 2731645_2734645
okay if you need to just do quit . 2734985_2737725
and quit out and try it again okay ? 2738445_2740265
edit just go down down you've got some numbers in there okay you put three numbers in so far . 2740805_2748745
yeah .
+, okay and you put one more once you've entered the last number go back you can either just start out again at stat and then you want calc . 2749305_2759025
mkay calc .
and whenever you get to this screen +/. 2759485_2762805
⌊ yeah ⌋ .
+, ⌈ you want this thing ⌉ (be)cause you can give different names to variables and you can keep (th)em saved just go down two with the down arrow key . 2764955_2769815
one two .
mhm +...
and then you want to specify number one f@l one . 2771415_2776455
one variable summary measures +... 2776655_2777835
which is calc . 2780155_2781115
oh okay +/.
+, mhm +/.
+, okay +/.
+, put one bar mhm .
&=start_simultaneous_conversation_one .
okay ?
thank you .
and again we're +//. 2783795_2787055
you know we're not +//. 2787375_2791035
with homework you have the time to be able to calculate these things . 2791625_2793745
mhm .
+, on an exam I'm not gonna have a list of twenty numbers so that someone who doesn't have the ability to do it with a calculator is gonna hafta sit there and do +/. 2794185_2800045
+, right .
+, all these squared things . 2800565_2801545
which &~on which one is standard deviation ? 2801645_2802765
you wanna use S (be)cause it's +/. 2803045_2804525
⌊ just ⌋ +/.
+, ⌈ always ⌉ gonna be a set of data . 2804525_2805425
like SX ? 2805705_2806185
yes ⌊ mhm ⌋ .
⌈ okay ⌉ .
+, ⌊ mhm ⌋ .
⌈ matched ⌉ pair for these matched pair &-um +... 2806425_2809445
when we have +//. 2809525_2811545
it says we have sixteen different plots but there's eight pairs so we use eight as the number right ? 2811985_2816105
&=end_simultaneous_conversation_one .
so do you know like for your &-um large samples when you use like the z@l test and then you have table three .
table what do you mean like with the Z chart ?
yeah .
yeah .
like this thing .
and then for the small ones you can use the T and then do you use this one .
right the T table .
okay and okay .
and then and small is supposed to be under thirty .
and you just use this .
&=end_simultaneous_conversation_two .
correct good and that's a common error that's done . 2816105_2818705
in pair design you always have pairing right ? 2819515_2822375
and even though I had eight farms with sixteen plots eight is still the number I use as my N . 2822795_2828755
as your N ? 2828875_2829215
because you're now really not looking at sixteen numbers you're gonna look at eight differences only . 2829335_2833395
so those are the number of observations you have . 2833955_2835695
so like how many pairs ⌊ we have ⌋ . 2835855_2837075
⌈ how many ⌉ pairs exactly correct ⌊ correct ⌋ . 2837075_2839335
⌈ &-um ⌉ a question I don't know how +//.
where to go look like if I wanna get a tutor like is there any way ⌊ or is it ⌋ . 2840435_2843675
⌈ well I saw ⌉ a card out there with a sign right outside my door +/. 2843675_2846035
⌊ okay ⌋ .
+, ⌈ you might ⌉ take a look at that otherwise some people advertise and if you +//. 2846375_2850255
&~i my head GSI has some names and I've been forwarding people who ask about a tutor to her and she gets them in contact and . 2851395_2856855
who's your head GSI ? 2857215_2857815
her name is Kim_Oanh but you can email me and I'll forward it to her too . 2857975_2861595
oh thank you so much . 2861875_2862495
mhm .
&-um I'm gonna go home and try and get this done ⌊ so ⌋ . 2863555_2866775
⌈ okay ⌉ where +//. 2866775_2867035
do you have the top one though so I can just make a note have you let your your GSI know at all what happened yet or not ? 2867475_2872575
I haven't (be)cause I was hoping I would just ⌊ be able to get it done ⌋ +/. 2872645_2874865
⌈ get it done ⌉ +/.
+, get it done ⌊ but ⌋ +/. 2874905_2875205
+, ⌈ mhm ⌉ .
+, I still might I have a few hours before my next class . 2876045_2879685
you have a funny story don't you ? 2880445_2881705
oh God .
share it with them so they know what it is . 2881745_2883885
&=laughs .
⌊ I have many bad stories about my stat homework ⌋ .
⌈ so ridiculous ⌉ . 2884205_2886405
<no no> no no this is so funny I went to visit my dad in Pennsylvania which is like a six hour drive away brought all +//. 2886965_2891885
first of all I'm the biggest nerd anyway &=laughs:S1 because I brought all of my stuff right ? 2892005_2895185
so I had my backpack full with like all the stuff that I need all of my stat stuff all the stuff for these tests that I had this week I get about halfway home about three hours into the drive and I'm like oh_my_god I left ⌊ my entire backpack ⌋ . 2895225_2907705
⌈ on top of the car ⌉ .
&~th no I left it at my dad's . 2908405_2909685
⌊ I'm like ⌋ +/. 2910065_2910325
⌈ oh ⌉ .
+, oh_my_god +/.
+, so I stopped I got off at an exit +//. 2910965_2913365
I didn't tell you this part I got off at an exit called him from a pay phone and he was laughing at me he's like I can't believe you left this here you must be freaking out . 2913505_2920085
I'm like mhm . 2920245_2920685
&=laughs:S8 so he he airmailed my backpack to me I got it yesterday afternoon but like I was already way behind in this and in &-uh all my other classes that I have tests in so +/. 2921025_2931285
+, oh +/.
+, whatever . 2932865_2933085
⌊ &~jee ⌋ .
⌈ listen ⌉ to my story I'm still ⌊ behind I ⌋ . 2933445_2934845
⌈ so funny ⌉ .
got this stomach infection I hadta go to the &~ho emergency room like this was like three weeks ago . 2935025_2939545
I'm still trying to catch up I missed an exam and I had a paper due and I got behind in stats I'm still like behind on my ⌊ stats like trying to catch up ⌋ . 2939885_2946285
⌈ oh life ⌉ .
⌊ but my GSI's like really nice ⌋ &=laughs:multiple . 2946445_2947605
then I still have to do this make up ⌈ test <it's just one thing> it's just one thing after another ⌉ . 2948595_2949715
⌊ we're never prepared are we ⌋ ? 2949715_2950795
college'll do it to you . 2951775_2952935
thank you . 2953015_2953435
I gotta go teach eleven but thank you . 2953515_2955195
thank you . 2955395_2955835
mhm .
⌈ should I ⌉ .
oh ⌊ I have ⌋ a question . 2956075_2957395
yes . 2957595_2957795
&=start_simultaneous_conversation_one .
&-um I have to +//. 2958095_2958515
and then I have to go away this weekend what should I do ? 2958755_2960955
I have to leave tomorrow morning so what should I do ? 2961035_2963075
I wanna +//. 2963175_2963455
I'm going on a plane and I wanna do a bunch of practice for stats +/. 2963655_2966655
⌈ mhm ⌉ .
+, ⌊ so ⌋ what &~sh what would you recommend ? 2966855_2967955
well I would look at the exam two that's in the back +/. 2968035_2970055
okay .
+, of your book &~a &~an ⌈ of the packet ⌉ . 2970515_2972235
⌊ of that model ⌋ ?
exactly &-um we are going through tentatively section six of chapter eleven okay ? 2972355_2977255
in terms of homework and so I'll be finishing that topic on Friday . 2977255_2979895
okay +/.
+, mhm .
+, sections +/.
+, &~se eleven +//.
&~se chapter eleven one through six .
+, okay .
+, mhm .
is that gonna be on the exam ?
yep mhm mhm +...
okay what do I need to sign so I can go teach ?
&=end_simultaneous_conversation_one .
to find like the p@l value on that do we just use this ?
you use your observed value that you got from the test statistic +/. 2979895_2981395
right .
+, and then you look that up <in the> in the table . 2982235_2983935
the t@l table or . 2985915_2987075
it depends on which test you did ⌈ if you did the ⌉ +/. 2987355_2989455
⌊ okay ⌋ .
+, the ⌈ t@l test ⌉ +/. 2989655_2990115
+, ⌊ t@l test use the ⌋ +/. 2990375_2990615
+, then you look it up in the t@l table . 2990615_2991675
+, okay +/. 2992075_2992215
+, the observed value that you got . 2992495_2993535
alright .
&=end_simultaneous_conversation_two .
so x@l bar is our d@l bar ? 2993535_2998595
oops sorry .
so if .
x@l bar is d@l bar if there were differences correct . 3004925_3006525
good .
okay SX equals &=recordingrelated_conversation . 3006945_3010045
&-um so if I for some reason can't turn it &~sh should I still email her or just . 3035025_3039645
well I wrote on the top but I would email her and let her know anyway just so it's &~a aware hi Kim . 3039645_3043385
this one's eight nine and twelve and &~i I actually +//. 3044305_3050225
but I'm doing chapters three and eleven this time +/. 3050725_3052785
mhm +/.
+, and &~it it doesn't even have the same chapters that I'm doing . 3052985_3055405
okay I I wrote you an email back and when it says homework eight it doesn't mean chapter eight . 3055425_3061325
&-uh I understand &~i ⌈ I looked into this edition and it doesn't have ⌉ +/. 3061845_3064605
⌊ <okay okay> okay okay ⌋ .
+, the same chapters . 3064945_3065325
well you can look on my computer (be)cause basically you just have to get into the server from last semester and I still don't +//. 3065925_3071525
will not guarantee that all the problems are there (be)cause ⌈ you know ⌉ . 3071725_3073865
⌊ I I think ⌋ I looked +//. 3073985_3074585
though +//.
but &~i I was working here yesterday but I couldn't +//. 3074865_3076865
somehow there's &~n not homework solutions ten in the server +... 3077445_3082465
or where they might be ?
I couldn't find the ⌈ solutions ⌉ . 3083385_3086205
⌊ can I check one answer ⌋ ? 3086525_3087725
mhm .
+, when +//.
do you have time to check .
I have to go teach at eleven and I'm ⌈ already a little late I'm sorry ⌉ . 3091005_3093465
⌊ okay never mind ⌋ .
&-um . 3093925_3094965
could I find you sometime later at maybe &~t around &-uh +//.
between two thirty and three ? 3095545_3100365
I'm here two thirty to three . 3100445_3101745
okay ?
alright .
+, and see if you can find it here or look on a different disk that maybe I have and if you +//. 3101745_3106325
but &-um you know I only have what I have and otherwise you'll have to type up some solutions okay ? 3107065_3110505
+, okay +/.
+, okay alrighty I'll leave this here in case you wanna come back but I'll be back between two and three . 3110885_3114945
+, okay ⌈ thank you ⌉ . 3115245_3115885
+, ⌊ okay ⌋ .
yep 